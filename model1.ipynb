{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faces2.0/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from FPN import Features, FPNetwork , classificationhead , bboxhead\n",
    "from Loss import Lossfunction\n",
    "from datasets import load_dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import  GradScaler\n",
    "from torch.amp import autocast\n",
    "import gc\n",
    "from dataset_convert import AnchorGenerator, FaceDetectionDataset\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model = model.features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"CUHK-CSE/wider_face\")\n",
    "train_dataset = dataset['train'].with_format(\"torch\")\n",
    "val_dataset = dataset['validation'].with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Features(model,['3','6', '13','18'])\n",
    "topdown = FPNetwork(out_channels=256)\n",
    "classifier = classificationhead(channels=256, num_anchors= 12, num_of_classes= 1)\n",
    "bboxregression = bboxhead(channels= 256 , num_anchors= 12)\n",
    "loss =Lossfunction()\n",
    "anchors = AnchorGenerator()\n",
    "data = FaceDetectionDataset(train_dataset,anchors)\n",
    "vali_data = FaceDetectionDataset(val_dataset,anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparametrs\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "learning_rate = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DataLoader(\n",
    "    data,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=4,     # Reduce if GPU memory is full\n",
    "    pin_memory=True,         # Faster CPU->GPU transfer\n",
    "    persistent_workers=True, # Reuse workers across epochs\n",
    "    prefetch_factor=4,       # Prefetch more batches\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = DataLoader(vali_data, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.03 GB\n",
      "Cached: 0.05 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.03 GB\n",
      "Cached: 0.05 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# epochs = 20\n",
    "# learning_rate = 1e-3\n",
    "def forward(p):\n",
    "    features = extractor.extract(p)\n",
    "    newfeatures = topdown(features)\n",
    "    output = {}\n",
    "    for key in list(newfeatures.keys()):\n",
    "        temp = {}\n",
    "        temp[\"bbox\"] = bboxregression(newfeatures[key])\n",
    "        temp[\"cls\"] = classifier(newfeatures[key])\n",
    "        output[key] = temp\n",
    "    return output\n",
    "\n",
    "def train(epochs:int,training_data , validation_data=None):\n",
    "    extractor.train()\n",
    "    topdown.train()\n",
    "    classifier.train()\n",
    "    bboxregression.train()\n",
    "    optimizer = optim.Adam(list(extractor.parameters())+\n",
    "                           list(topdown.parameters())+\n",
    "                           list(classifier.parameters())+\n",
    "                           list(bboxregression.parameters()), lr=learning_rate)\n",
    "    loSS = {}\n",
    "    for i in range (0,epochs):\n",
    "        train_loss= 0\n",
    "        for key, (image,bbox) in enumerate(training_data):\n",
    "            epoch_loss = {}\n",
    "            model_pred = forward(image)\n",
    "            optimizer.zero_grad()\n",
    "            ll = loss(model_pred, bbox)\n",
    "            train_loss+=ll\n",
    "            if (key % 10 == 0):\n",
    "                epoch_loss[key] = train_loss/10\n",
    "                print(f\"The avg loss for {key}th data is {train_loss/10}\")\n",
    "                train_loss = 0    \n",
    "            ll.backward()\n",
    "            optimizer.step()\n",
    "        loSS[i] = epoch_loss\n",
    "    return loSS\n",
    "\n",
    "# train(epochs=epochs,training_data=training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7452536\n"
     ]
    }
   ],
   "source": [
    "total_params=sum(p.numel() for p in extractor.parameters())\n",
    "total_params+= sum(p.numel() for p in topdown.parameters())\n",
    "total_params+= sum(p.numel() for p in classifier.parameters())\n",
    "total_params+= sum(p.numel() for p in bboxregression.parameters())\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/faces2.0/.conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/faces2.0/.conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/faces2.0/.conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1443\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1444\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1445\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/faces2.0/.conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/faces2.0/.conda/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/faces2.0/.conda/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-84 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 61, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/faces2.0/.conda/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (image, bbox) in enumerate(training_data):\n",
    "    print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7529/4292142752.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_accumulation(epochs: int, training_data, validation_data=None, accumulation_steps=4):\n",
    "    # Set models to training mode\n",
    "    extractor.train()\n",
    "    topdown.train()\n",
    "    classifier.train()\n",
    "    bboxregression.train()\n",
    "    \n",
    "    # Enable gradient checkpointing\n",
    "    if hasattr(extractor, 'gradient_checkpointing_enable'):\n",
    "        extractor.gradient_checkpointing_enable()\n",
    "    if hasattr(topdown, 'gradient_checkpointing_enable'):\n",
    "        topdown.gradient_checkpointing_enable()\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        list(extractor.parameters()) +\n",
    "        list(topdown.parameters()) +\n",
    "        list(classifier.parameters()) +\n",
    "        list(bboxregression.parameters()), \n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    loss_history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for batch_idx, (image, bbox) in enumerate(training_data):\n",
    "            # Mixed precision forward pass\n",
    "            \n",
    "            with autocast('cuda'):\n",
    "                model_pred = forward(image.cuda())\n",
    "                ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "            \n",
    "            # Backward pass\n",
    "            scaler.scale(ll).backward()\n",
    "            \n",
    "            # Step optimizer every accumulation_steps\n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Accumulate loss\n",
    "            batch_loss = ll.item() * accumulation_steps  # Unscale for logging\n",
    "            epoch_loss += batch_loss\n",
    "            running_loss += batch_loss\n",
    "            batch_count += 1\n",
    "            \n",
    "            # Print progress\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                avg_running_loss = running_loss / 10\n",
    "                print(f\"Batch {batch_idx + 1}: Avg Loss = {avg_running_loss:.6f}\")\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            # Memory cleanup\n",
    "            del model_pred, ll\n",
    "            # if batch_idx % 2 == 0:\n",
    "            #     print(batch_idx)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "                \n",
    "        if batch_count % accumulation_steps != 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "        loss_history[epoch] = avg_epoch_loss\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1} Average Loss: {avg_epoch_loss:.6f}\")\n",
    "        \n",
    "        # Cleanup at epoch end\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "------------------------------\n",
      "Batch 10: Avg Loss = 0.203439\n",
      "Batch 20: Avg Loss = 0.208533\n",
      "Batch 30: Avg Loss = 0.195186\n",
      "Batch 40: Avg Loss = 0.200683\n",
      "Batch 50: Avg Loss = 0.201015\n",
      "Batch 60: Avg Loss = 0.197957\n",
      "Batch 70: Avg Loss = 0.193251\n",
      "Batch 80: Avg Loss = 0.191482\n",
      "Batch 90: Avg Loss = 0.187896\n",
      "Batch 100: Avg Loss = 0.184743\n",
      "Batch 110: Avg Loss = 0.190637\n",
      "Batch 120: Avg Loss = 0.183515\n",
      "Batch 130: Avg Loss = 0.181475\n",
      "Batch 140: Avg Loss = 0.180039\n",
      "Batch 150: Avg Loss = 0.183782\n",
      "Batch 160: Avg Loss = 0.178398\n",
      "Batch 170: Avg Loss = 0.178592\n",
      "Batch 180: Avg Loss = 0.176566\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lossdata = train_with_accumulation(epochs = 5, training_data = training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 22.24 GB\n",
      "Cached: 22.44 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 640])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1000][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p =(s['18']['cls'].squeeze(0).squeeze(0).T>0.5).cpu().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4036)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=forward(data[1000][0].unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100][1][0]['bbox_targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4933, 0.5469, 0.4821, 0.4534],\n",
       "        [0.4507, 0.4666, 0.4542, 0.4803],\n",
       "        [0.4810, 0.4796, 0.4658, 0.4742],\n",
       "        ...,\n",
       "        [0.4389, 0.0000, 0.4425, 0.0434],\n",
       "        [0.4311, 0.0000, 0.4414, 0.0056],\n",
       "        [0.4147, 0.0000, 0.3418, 0.0000]], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['18']['bbox'].squeeze(0).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1751, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(data[1000][1][0]['bbox_targets'] - s['18']['bbox'].squeeze(0).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(extractor.state_dict(),'/home/faces2.0/models/extractor.pt')\n",
    "torch.save(topdown.state_dict(),'/home/faces2.0/models/topdown.pt')\n",
    "torch.save(classifier.state_dict(),'/home/faces2.0/models/classifier.pt')\n",
    "torch.save(bboxregression.state_dict(),'/home/faces2.0/models/bboxregression.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
