{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faces2.0/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from FPN import Features, FPNetwork , classificationhead , bboxhead\n",
    "from Loss import Lossfunction\n",
    "from datasets import load_dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import  GradScaler\n",
    "from torch.amp import autocast\n",
    "import gc\n",
    "from dataset_convert import AnchorGenerator, FaceDetectionDataset\n",
    "# device = torch.device(\"mps\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model = model.features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"CUHK-CSE/wider_face\")\n",
    "train_dataset = dataset['train'].with_format(\"torch\")\n",
    "val_dataset = dataset['validation'].with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[237, 237, 237,  ..., 248, 255, 243],\n",
       "          [ 59,  59,  59,  ..., 168, 250, 255],\n",
       "          [ 37,  37,  37,  ..., 162, 255, 255],\n",
       "          ...,\n",
       "          [ 67,  66,  64,  ..., 156, 255, 254],\n",
       "          [ 74,  72,  68,  ..., 156, 255, 254],\n",
       "          [ 72,  70,  67,  ..., 156, 255, 255]],\n",
       " \n",
       "         [[251, 251, 251,  ..., 250, 255, 243],\n",
       "          [ 72,  72,  72,  ..., 169, 249, 255],\n",
       "          [ 50,  50,  50,  ..., 162, 254, 255],\n",
       "          ...,\n",
       "          [ 73,  72,  70,  ..., 156, 255, 253],\n",
       "          [ 80,  78,  74,  ..., 156, 255, 253],\n",
       "          [ 78,  76,  73,  ..., 156, 255, 254]],\n",
       " \n",
       "         [[255, 255, 255,  ..., 249, 250, 233],\n",
       "          [106, 106, 106,  ..., 173, 245, 247],\n",
       "          [ 94,  94,  94,  ..., 172, 255, 253],\n",
       "          ...,\n",
       "          [ 35,  34,  32,  ..., 146, 247, 248],\n",
       "          [ 42,  40,  36,  ..., 146, 247, 248],\n",
       "          [ 40,  38,  35,  ..., 146, 248, 249]]], dtype=torch.uint8),\n",
       " 'faces': {'bbox': tensor([[449., 330., 122., 149.]]),\n",
       "  'blur': tensor([0]),\n",
       "  'expression': tensor([0]),\n",
       "  'illumination': tensor([0]),\n",
       "  'occlusion': tensor([0]),\n",
       "  'pose': tensor([0]),\n",
       "  'invalid': tensor([False])}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Features(model,['3','6', '13','18'])\n",
    "topdown = FPNetwork(out_channels=256)\n",
    "classifier = classificationhead(channels=256, num_anchors= 12, num_of_classes= 1)\n",
    "bboxregression = bboxhead(channels= 256 , num_anchors= 12)\n",
    "loss =Lossfunction(lambd=10)\n",
    "anchors = AnchorGenerator()\n",
    "data = FaceDetectionDataset(train_dataset,anchors)\n",
    "vali_data = FaceDetectionDataset(val_dataset,anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.04 GB\n",
      "Cached: 0.05 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.04 GB\n",
      "Cached: 0.05 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# epochs = 20\n",
    "# learning_rate = 1e-3\n",
    "def forward(p):\n",
    "    features = extractor.extract(p)\n",
    "    newfeatures = topdown(features)\n",
    "    output = {}\n",
    "    for key in list(newfeatures.keys()):\n",
    "        temp = {}\n",
    "        temp[\"bbox\"] = bboxregression(newfeatures[key])\n",
    "        temp[\"cls\"] = classifier(newfeatures[key])\n",
    "        output[key] = temp\n",
    "    return output\n",
    "\n",
    "def train(epochs:int,training_data , validation_data=None):\n",
    "    extractor.train()\n",
    "    topdown.train()\n",
    "    classifier.train()\n",
    "    bboxregression.train()\n",
    "    optimizer = optim.Adam(list(extractor.parameters())+\n",
    "                           list(topdown.parameters())+\n",
    "                           list(classifier.parameters())+\n",
    "                           list(bboxregression.parameters()), lr=learning_rate)\n",
    "    loSS = {}\n",
    "    for i in range (0,epochs):\n",
    "        train_loss= 0\n",
    "        for key, (image,bbox) in enumerate(training_data):\n",
    "            epoch_loss = {}\n",
    "            model_pred = forward(image.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            ll = loss(model_pred, bbox)\n",
    "            del image , model_pred , bbox\n",
    "\n",
    "            train_loss+=ll\n",
    "            if (key % 1 == 0):\n",
    "                epoch_loss[key] = train_loss/10\n",
    "                print(f\"The avg loss for {key}th data is {train_loss/10}\")\n",
    "                train_loss = 0   \n",
    "            if key == 4:\n",
    "                    break\n",
    "            ll.backward()\n",
    "            optimizer.step()\n",
    "            del ll\n",
    "        loSS[i] = epoch_loss\n",
    "        del epoch_loss\n",
    "    return loSS\n",
    "\n",
    "# train(epochs=epochs,training_data=training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9818964\n"
     ]
    }
   ],
   "source": [
    "total_params=sum(p.numel() for p in extractor.parameters())\n",
    "total_params+= sum(p.numel() for p in topdown.parameters())\n",
    "total_params+= sum(p.numel() for p in classifier.parameters())\n",
    "total_params+= sum(p.numel() for p in bboxregression.parameters())\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_882/4292142752.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "\n",
    "def train_with_accumulation(epochs: int, training_data, validation_data=None, accumulation_steps=4):\n",
    "    # Set models to training mode\n",
    "    extractor.train()\n",
    "    topdown.train()\n",
    "    classifier.train()\n",
    "    bboxregression.train()\n",
    "    \n",
    "    # Enable gradient checkpointing\n",
    "    if hasattr(extractor, 'gradient_checkpointing_enable'):\n",
    "        extractor.gradient_checkpointing_enable()\n",
    "    if hasattr(topdown, 'gradient_checkpointing_enable'):\n",
    "        topdown.gradient_checkpointing_enable()\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        list(extractor.parameters()) +\n",
    "        list(topdown.parameters()) +\n",
    "        list(classifier.parameters()) +\n",
    "        list(bboxregression.parameters()), \n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    loss_history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        try:\n",
    "            for batch_idx, (image, bbox) in enumerate(training_data):\n",
    "                # Mixed precision forward pass\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with autocast('cuda'):\n",
    "                    model_pred = forward(image.cuda())\n",
    "                    ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "                # del image , model_pred , bbox\n",
    "                # Backward pass\n",
    "                scaler.scale(ll).backward()\n",
    "                \n",
    "                # Step optimizer every accumulation_steps\n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                # Accumulate loss\n",
    "                batch_loss = ll.item() * accumulation_steps  # Unscale for logging\n",
    "                epoch_loss += batch_loss\n",
    "                running_loss += batch_loss\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Print progress\n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    avg_running_loss = running_loss / 10\n",
    "                    # print(\"-\" * 30)\n",
    "                    print(f\"Batch {batch_idx + 1}: Avg Loss = {avg_running_loss:.6f}\")\n",
    "                    # print(\"-\" * 30)\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                # Memory \n",
    "                del image , model_pred , bbox\n",
    "\n",
    "                del ll\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "        except Exception as e :\n",
    "            print (e)\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "            break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"INTERRUPTED!!\")\n",
    "            return loss_history   \n",
    "\n",
    "                \n",
    "        if batch_count % accumulation_steps != 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "        loss_history[epoch] = avg_epoch_loss\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Epoch {epoch + 1} Average Loss: {avg_epoch_loss:.6f}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        \n",
    "        # Cleanup at epoch end\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "training_data = DataLoader(\n",
    "    data,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=4,     # Reduce if GPU memory is full\n",
    "    pin_memory=True,         # Faster CPU->GPU transfer\n",
    "    persistent_workers=True, # Reuse workers across epochs\n",
    "    prefetch_factor=4,       # Prefetch more batches\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "validation_data = DataLoader(vali_data,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=4,     # Reduce if GPU memory is full\n",
    "    pin_memory=True,         # Faster CPU->GPU transfer\n",
    "    persistent_workers=True, # Reuse workers across epochs\n",
    "    prefetch_factor=4,       # Prefetch more batches\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = list(classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10: Avg Loss = 460.772297\n",
      "Batch 20: Avg Loss = 140.993696\n",
      "Batch 30: Avg Loss = 200.815022\n",
      "Batch 40: Avg Loss = 158.538258\n",
      "Batch 50: Avg Loss = 149.542924\n",
      "Batch 60: Avg Loss = 202.118232\n",
      "Batch 70: Avg Loss = 131.681020\n",
      "Batch 80: Avg Loss = 3440.989156\n",
      "Batch 90: Avg Loss = 277.677647\n",
      "Batch 100: Avg Loss = 165.439429\n",
      "Batch 110: Avg Loss = 233.053395\n",
      "Batch 120: Avg Loss = 194.951407\n",
      "Batch 130: Avg Loss = 158.863708\n",
      "Batch 140: Avg Loss = 205.299765\n",
      "Batch 150: Avg Loss = 223.091113\n",
      "Batch 160: Avg Loss = 161.764712\n",
      "Batch 170: Avg Loss = 121.819528\n",
      "Batch 180: Avg Loss = 413.141696\n",
      "Batch 190: Avg Loss = 244.212051\n",
      "Batch 200: Avg Loss = 169.700817\n",
      "Batch 210: Avg Loss = 286.633378\n",
      "Batch 220: Avg Loss = 170.158089\n",
      "Batch 230: Avg Loss = 155.058964\n",
      "Batch 240: Avg Loss = 131.824800\n",
      "Batch 250: Avg Loss = 433.727970\n",
      "Batch 260: Avg Loss = 162.855054\n",
      "Batch 270: Avg Loss = 263.327998\n",
      "Batch 280: Avg Loss = 3278.883255\n",
      "Batch 290: Avg Loss = 3203.168296\n",
      "Batch 300: Avg Loss = 139.934084\n",
      "Batch 310: Avg Loss = 119.224848\n",
      "Batch 320: Avg Loss = 363.797011\n",
      "Batch 330: Avg Loss = 179.904199\n",
      "Batch 340: Avg Loss = 160.486127\n",
      "Batch 350: Avg Loss = 128.370669\n",
      "Batch 360: Avg Loss = 208.541989\n",
      "Batch 370: Avg Loss = 452.260851\n",
      "Batch 380: Avg Loss = 190.073367\n",
      "Batch 390: Avg Loss = 201.728914\n",
      "Batch 400: Avg Loss = 233.010126\n",
      "Batch 410: Avg Loss = 122.258806\n",
      "Batch 420: Avg Loss = 124.574144\n",
      "Batch 430: Avg Loss = 600.312526\n",
      "Batch 440: Avg Loss = 274.550690\n",
      "Batch 450: Avg Loss = 164.986033\n",
      "Batch 460: Avg Loss = 137.671818\n",
      "Batch 470: Avg Loss = 180.960353\n",
      "Batch 480: Avg Loss = 3117.584207\n",
      "Batch 490: Avg Loss = 337.535254\n",
      "Batch 500: Avg Loss = 127.081059\n",
      "Batch 510: Avg Loss = 142.654361\n",
      "Batch 520: Avg Loss = 178.780125\n",
      "Batch 530: Avg Loss = 135.101825\n",
      "Batch 540: Avg Loss = 184.276654\n",
      "Batch 550: Avg Loss = 114.739162\n",
      "Batch 560: Avg Loss = 203.061240\n",
      "Batch 570: Avg Loss = 161.246006\n",
      "Batch 580: Avg Loss = 114.163509\n",
      "Batch 590: Avg Loss = 151.876398\n",
      "Batch 600: Avg Loss = 293.389969\n",
      "Batch 610: Avg Loss = 153.263812\n",
      "Batch 620: Avg Loss = 93.974741\n",
      "Batch 630: Avg Loss = 263.913515\n",
      "Batch 640: Avg Loss = 3037.713721\n",
      "Batch 650: Avg Loss = 391.761899\n",
      "Batch 660: Avg Loss = 188.681822\n",
      "Batch 670: Avg Loss = 151.894178\n",
      "Batch 680: Avg Loss = 179.878875\n",
      "Batch 690: Avg Loss = 229.278476\n",
      "Batch 700: Avg Loss = 211.637942\n",
      "Batch 710: Avg Loss = 344.718645\n",
      "Batch 720: Avg Loss = 125.029763\n",
      "Batch 730: Avg Loss = 174.944122\n",
      "Batch 740: Avg Loss = 116.660324\n",
      "Batch 750: Avg Loss = 147.273677\n",
      "Batch 760: Avg Loss = 281.439083\n",
      "Batch 770: Avg Loss = 178.078003\n",
      "Batch 780: Avg Loss = 133.029201\n",
      "Batch 790: Avg Loss = 129.145963\n",
      "Batch 800: Avg Loss = 186.673196\n",
      "Batch 810: Avg Loss = 152.163506\n",
      "Batch 820: Avg Loss = 91.091564\n",
      "Batch 830: Avg Loss = 3026.629361\n",
      "Batch 840: Avg Loss = 2986.901871\n",
      "Batch 850: Avg Loss = 195.363880\n",
      "Batch 860: Avg Loss = 187.344097\n",
      "Batch 870: Avg Loss = 198.844133\n",
      "Batch 880: Avg Loss = 113.905358\n",
      "Batch 890: Avg Loss = 199.936209\n",
      "Batch 900: Avg Loss = 113.643001\n",
      "Batch 910: Avg Loss = 3012.098756\n",
      "Batch 920: Avg Loss = 3002.139061\n",
      "Batch 930: Avg Loss = 103.161777\n",
      "Batch 940: Avg Loss = 117.343887\n",
      "Batch 950: Avg Loss = 141.330302\n",
      "Batch 960: Avg Loss = 242.314279\n",
      "Batch 970: Avg Loss = 148.489521\n",
      "Batch 980: Avg Loss = 148.642947\n",
      "Batch 990: Avg Loss = 188.447970\n",
      "Batch 1000: Avg Loss = 146.307569\n",
      "Batch 1010: Avg Loss = 933.668128\n",
      "Batch 1020: Avg Loss = 114.730111\n",
      "Batch 1030: Avg Loss = 155.685971\n",
      "Batch 1040: Avg Loss = 184.954492\n",
      "Batch 1050: Avg Loss = 148.243480\n",
      "Batch 1060: Avg Loss = 878.014553\n",
      "Batch 1070: Avg Loss = 238.251238\n",
      "Batch 1080: Avg Loss = 133.273885\n",
      "Batch 1090: Avg Loss = 1503.030910\n",
      "Batch 1100: Avg Loss = 128.926913\n",
      "Batch 1110: Avg Loss = 220.033281\n",
      "Batch 1120: Avg Loss = 199.032323\n",
      "Batch 1130: Avg Loss = 166.296532\n",
      "Batch 1140: Avg Loss = 228.979189\n",
      "Batch 1150: Avg Loss = 188.029106\n",
      "Batch 1160: Avg Loss = 282.210365\n",
      "Batch 1170: Avg Loss = 135.188667\n",
      "Batch 1180: Avg Loss = 103.629556\n",
      "Batch 1190: Avg Loss = 151.624697\n",
      "Batch 1200: Avg Loss = 175.200621\n",
      "Batch 1210: Avg Loss = 306.866213\n",
      "Batch 1220: Avg Loss = 119.593233\n",
      "Batch 1230: Avg Loss = 215.361884\n",
      "Batch 1240: Avg Loss = 220.937809\n",
      "Batch 1250: Avg Loss = 111.097883\n",
      "Batch 1260: Avg Loss = 166.443476\n",
      "Batch 1270: Avg Loss = 138.604694\n",
      "Batch 1280: Avg Loss = 106.216906\n",
      "Batch 1290: Avg Loss = 221.705373\n",
      "Batch 1300: Avg Loss = 186.726781\n",
      "Batch 1310: Avg Loss = 158.525282\n",
      "Batch 1320: Avg Loss = 94.986589\n",
      "Batch 1330: Avg Loss = 162.820334\n",
      "Batch 1340: Avg Loss = 121.144595\n",
      "Batch 1350: Avg Loss = 287.317113\n",
      "Batch 1360: Avg Loss = 893.574708\n",
      "Batch 1370: Avg Loss = 161.584964\n",
      "Batch 1380: Avg Loss = 126.000189\n",
      "Batch 1390: Avg Loss = 190.866023\n",
      "Batch 1400: Avg Loss = 226.757697\n",
      "Batch 1410: Avg Loss = 117.131467\n",
      "Batch 1420: Avg Loss = 110.823399\n",
      "Batch 1430: Avg Loss = 181.010120\n",
      "Batch 1440: Avg Loss = 129.136166\n",
      "Batch 1450: Avg Loss = 150.602796\n",
      "Batch 1460: Avg Loss = 217.754898\n",
      "Batch 1470: Avg Loss = 125.751353\n",
      "Batch 1480: Avg Loss = 154.766062\n",
      "Batch 1490: Avg Loss = 153.673272\n",
      "Batch 1500: Avg Loss = 165.920837\n",
      "Batch 1510: Avg Loss = 217.800840\n",
      "Batch 1520: Avg Loss = 2979.268977\n",
      "Batch 1530: Avg Loss = 212.335382\n",
      "Batch 1540: Avg Loss = 172.968213\n",
      "Batch 1550: Avg Loss = 377.550520\n",
      "Batch 1560: Avg Loss = 134.665527\n",
      "Batch 1570: Avg Loss = 136.262525\n",
      "Batch 1580: Avg Loss = 161.049745\n",
      "Batch 1590: Avg Loss = 128.784608\n",
      "Batch 1600: Avg Loss = 2892.879794\n",
      "Batch 1610: Avg Loss = 368.982203\n",
      "------------------------------\n",
      "Epoch 1 Average Loss: 408.662015\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "lossdata = train_with_accumulation(epochs = 1, training_data = training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Lossfunction()\n",
    "extractor.eval()\n",
    "topdown.eval()\n",
    "classifier.eval()\n",
    "bboxregression.eval()\n",
    "accumulation_steps = 4\n",
    "for batch_idx, (image, bbox) in enumerate(validation_data):\n",
    "\n",
    "    with autocast('cuda'):\n",
    "        model_pred = forward(image.cuda())\n",
    "        ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "    del image , model_pred , bbox\n",
    "    print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 2.11 GB\n",
      "Cached: 2.21 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 640])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1000][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=forward(data[200][0].unsqueeze(0).cuda())\n",
    "t= data[200][1]\n",
    "ls = loss(s,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(106.7692, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t[1]['cls_targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9428.2197, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s['3']['bbox'].cpu()-t[3]['bbox_targets']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s['3']['cls'].cpu()>0.9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2211],\n",
       "         [0.2228],\n",
       "         [0.2230],\n",
       "         ...,\n",
       "         [0.2234],\n",
       "         [0.2228],\n",
       "         [0.2218]]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid((s['3']['cls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         ...,\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[-1]['cls_targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = loss(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9703, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4933, 0.5469, 0.4821, 0.4534],\n",
       "        [0.4507, 0.4666, 0.4542, 0.4803],\n",
       "        [0.4810, 0.4796, 0.4658, 0.4742],\n",
       "        ...,\n",
       "        [0.4389, 0.0000, 0.4425, 0.0434],\n",
       "        [0.4311, 0.0000, 0.4414, 0.0056],\n",
       "        [0.4147, 0.0000, 0.3418, 0.0000]], grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['18']['bbox'].squeeze(0).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1751, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(data[1000][1][0]['bbox_targets'] - s['18']['bbox'].squeeze(0).cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model3 = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model3 = model3.features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m torch.all((\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[31mRuntimeError\u001b[39m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "torch.all(list(extractor.parameters()) == list(model3.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(extractor.state_dict(),'/home/faces2.0/models/extractor.pt')\n",
    "torch.save(topdown.state_dict(),'/home/faces2.0/models/topdown.pt')\n",
    "torch.save(classifier.state_dict(),'/home/faces2.0/models/classifier.pt')\n",
    "torch.save(bboxregression.state_dict(),'/home/faces2.0/models/bboxregression.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
