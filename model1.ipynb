{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faces2.0/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_772/3959396688.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from FPN import Features, FPNetwork , classificationhead , bboxhead\n",
    "from Loss import Lossfunction\n",
    "from datasets import load_dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import  GradScaler\n",
    "from torch.amp import autocast\n",
    "import gc\n",
    "from dataset_convert import AnchorGenerator, FaceDetectionDataset\n",
    "import random\n",
    "scaler = GradScaler()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /home/.cache/torch/hub/torchhub.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://api.ngc.nvidia.com/v2/models/nvidia/resnet50_pyt_amp/versions/20.06.0/files/nvidia_resnet50_200821.pth.tar\" to /home/.cache/torch/hub/checkpoints/nvidia_resnet50_200821.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.7M/97.7M [00:01<00:00, 91.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "\n",
    "resnet_backbone = nn.Sequential(*list(resnet50.children())[:-2]).to(device)\n",
    "layers_r50= {'4.0':256,  #-> (160,160)\n",
    "             '4.1':512,  #-> (80,80)\n",
    "             '4.2':1024, #-> (40,40)\n",
    "             '4.3':2048  #-> (20,20)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vipulagarwal/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model = model.features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 12880/12880 [00:02<00:00, 5310.65 examples/s]\n",
      "Generating test split: 100%|██████████| 16097/16097 [00:00<00:00, 21002.96 examples/s]\n",
      "Generating validation split: 100%|██████████| 3226/3226 [00:00<00:00, 5392.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"CUHK-CSE/wider_face\")\n",
    "train_dataset = dataset['train'].with_format(\"torch\")\n",
    "val_dataset = dataset['validation'].with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Features(resnet_backbone,layers=list(layers_r50.keys()))\n",
    "topdown = FPNetwork(in_channels=layers_r50, out_channels=256)\n",
    "classifier = classificationhead(channels=256, num_anchors= 12, num_of_classes= 1)\n",
    "bboxregression = bboxhead(channels= 256 , num_anchors= 12)\n",
    "loss =Lossfunction(lambd=1)\n",
    "anchors = AnchorGenerator()\n",
    "data = FaceDetectionDataset(train_dataset,anchors)\n",
    "vali_data = FaceDetectionDataset(val_dataset,anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor = Features(model,['3','6', '13','18'])\n",
    "# topdown = FPNetwork(out_channels=256)\n",
    "# classifier = classificationhead(channels=256, num_anchors= 12, num_of_classes= 1)\n",
    "# bboxregression = bboxhead(channels= 256 , num_anchors= 12)\n",
    "# loss =Lossfunction(lambd=10)\n",
    "# anchors = AnchorGenerator()\n",
    "# data = FaceDetectionDataset(train_dataset,anchors)\n",
    "# vali_data = FaceDetectionDataset(val_dataset,anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.00 GB\n",
      "Cached: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(p):\n",
    "    features = extractor.extract(p)\n",
    "    newfeatures = topdown(features)\n",
    "    output = {}\n",
    "    for key in list(newfeatures.keys()):\n",
    "        temp = {}\n",
    "        temp[\"bbox\"] = bboxregression(newfeatures[key])\n",
    "        temp[\"cls\"] = classifier(newfeatures[key])\n",
    "        output[key] = temp\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7871, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=random.randint(0,1200)\n",
    "kk =data[i][0].unsqueeze(0).to(device)\n",
    "jk = forward(kk)\n",
    "ll = loss(jk, data[i][1])\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.6243],\n",
       "         [-3.5365],\n",
       "         [-3.9273],\n",
       "         [-3.4183],\n",
       "         [-3.9731],\n",
       "         [-3.7400],\n",
       "         [-3.8969],\n",
       "         [-3.8171],\n",
       "         [-3.6029],\n",
       "         [-3.2696],\n",
       "         [-3.3121],\n",
       "         [-3.5310],\n",
       "         [-3.3870],\n",
       "         [-3.3835],\n",
       "         [-3.3399],\n",
       "         [-3.4736],\n",
       "         [-3.6334],\n",
       "         [-3.8824],\n",
       "         [-3.5717],\n",
       "         [-3.1045],\n",
       "         [-3.5244],\n",
       "         [-3.5147],\n",
       "         [-3.6700],\n",
       "         [-3.6975],\n",
       "         [-3.8044],\n",
       "         [-4.3616],\n",
       "         [-3.8088],\n",
       "         [-3.9572],\n",
       "         [-3.3879],\n",
       "         [-3.8553],\n",
       "         [-4.2100],\n",
       "         [-3.6968],\n",
       "         [-3.3975],\n",
       "         [-3.6694],\n",
       "         [-3.8204],\n",
       "         [-3.8736],\n",
       "         [-3.6786],\n",
       "         [-3.9293],\n",
       "         [-3.8306],\n",
       "         [-3.4526],\n",
       "         [-3.3792],\n",
       "         [-3.3392],\n",
       "         [-3.3587],\n",
       "         [-3.3264],\n",
       "         [-3.8113],\n",
       "         [-4.0264],\n",
       "         [-3.8518],\n",
       "         [-3.7846],\n",
       "         [-2.9091],\n",
       "         [-3.5213],\n",
       "         [-3.7587],\n",
       "         [-3.7370],\n",
       "         [-3.4949],\n",
       "         [-3.3453],\n",
       "         [-3.2512],\n",
       "         [-3.4802],\n",
       "         [-3.3614],\n",
       "         [-3.3432],\n",
       "         [-3.4287],\n",
       "         [-3.1662],\n",
       "         [-3.2067],\n",
       "         [-3.1785],\n",
       "         [-3.2949],\n",
       "         [-3.0519],\n",
       "         [-3.5189],\n",
       "         [-3.7491],\n",
       "         [-3.7648],\n",
       "         [-3.8872],\n",
       "         [-3.7485],\n",
       "         [-3.8610],\n",
       "         [-4.2377],\n",
       "         [-3.5651],\n",
       "         [-3.9865],\n",
       "         [-3.4735],\n",
       "         [-3.1760],\n",
       "         [-3.2645],\n",
       "         [-3.0749],\n",
       "         [-3.4765],\n",
       "         [-3.5070],\n",
       "         [-3.4058],\n",
       "         [-3.2717],\n",
       "         [-3.8215],\n",
       "         [-3.6500],\n",
       "         [-3.2575],\n",
       "         [-3.9542],\n",
       "         [-3.4464],\n",
       "         [-4.1523],\n",
       "         [-3.7976],\n",
       "         [-3.7545],\n",
       "         [-3.2636],\n",
       "         [-3.8678],\n",
       "         [-3.2377],\n",
       "         [-3.4230],\n",
       "         [-3.2112],\n",
       "         [-3.2401],\n",
       "         [-3.1167],\n",
       "         [-3.3913],\n",
       "         [-3.5952],\n",
       "         [-3.4501],\n",
       "         [-3.4676],\n",
       "         [-3.8795],\n",
       "         [-3.9229],\n",
       "         [-3.4062],\n",
       "         [-3.9471],\n",
       "         [-4.4227],\n",
       "         [-3.7630],\n",
       "         [-3.9694],\n",
       "         [-3.3107],\n",
       "         [-3.2467],\n",
       "         [-2.8813],\n",
       "         [-3.4357],\n",
       "         [-3.0232],\n",
       "         [-3.5199],\n",
       "         [-3.1568],\n",
       "         [-3.1304],\n",
       "         [-2.9260],\n",
       "         [-3.3971],\n",
       "         [-3.2470],\n",
       "         [-3.2505],\n",
       "         [-3.5091],\n",
       "         [-2.8310],\n",
       "         [-4.2719],\n",
       "         [-4.0310],\n",
       "         [-3.9725],\n",
       "         [-4.5019],\n",
       "         [-3.5400],\n",
       "         [-3.4561],\n",
       "         [-2.9656],\n",
       "         [-2.9882],\n",
       "         [-3.0151],\n",
       "         [-3.2164],\n",
       "         [-3.6860],\n",
       "         [-3.2670],\n",
       "         [-3.2865],\n",
       "         [-3.3781],\n",
       "         [-3.3568],\n",
       "         [-2.8112],\n",
       "         [-3.4017],\n",
       "         [-3.4868],\n",
       "         [-3.2189],\n",
       "         [-3.8205],\n",
       "         [-3.7453],\n",
       "         [-4.5402],\n",
       "         [-3.5053],\n",
       "         [-4.8591],\n",
       "         [-4.3479],\n",
       "         [-3.5244],\n",
       "         [-4.3908],\n",
       "         [-3.5634],\n",
       "         [-2.7797],\n",
       "         [-2.7259],\n",
       "         [-3.6044],\n",
       "         [-3.4108],\n",
       "         [-2.9299],\n",
       "         [-2.6574],\n",
       "         [-3.1437],\n",
       "         [-2.9018],\n",
       "         [-2.9536],\n",
       "         [-3.3261],\n",
       "         [-3.0929],\n",
       "         [-4.2389],\n",
       "         [-3.4087],\n",
       "         [-4.3607],\n",
       "         [-4.8878],\n",
       "         [-4.2454],\n",
       "         [-4.3995],\n",
       "         [-4.1036],\n",
       "         [-3.2001],\n",
       "         [-3.5715],\n",
       "         [-3.2086],\n",
       "         [-2.8349],\n",
       "         [-3.3008],\n",
       "         [-3.3714],\n",
       "         [-3.0501],\n",
       "         [-3.2339],\n",
       "         [-2.7959],\n",
       "         [-3.5688],\n",
       "         [-3.0005],\n",
       "         [-2.4915],\n",
       "         [-3.2019],\n",
       "         [-3.5022],\n",
       "         [-3.5202],\n",
       "         [-5.2024],\n",
       "         [-4.6753],\n",
       "         [-4.4549],\n",
       "         [-3.7284],\n",
       "         [-3.4322],\n",
       "         [-3.8219],\n",
       "         [-3.7413],\n",
       "         [-3.7680],\n",
       "         [-3.4808],\n",
       "         [-3.4912],\n",
       "         [-3.2777],\n",
       "         [-3.0649],\n",
       "         [-3.0766],\n",
       "         [-3.0452],\n",
       "         [-3.1485],\n",
       "         [-3.3975],\n",
       "         [-3.2285],\n",
       "         [-3.3350],\n",
       "         [-3.3194],\n",
       "         [-2.5733],\n",
       "         [-5.0413],\n",
       "         [-4.7331],\n",
       "         [-4.2428],\n",
       "         [-3.2881],\n",
       "         [-2.8404],\n",
       "         [-3.5740],\n",
       "         [-2.6989],\n",
       "         [-3.4631],\n",
       "         [-3.9452],\n",
       "         [-2.9769],\n",
       "         [-3.3046],\n",
       "         [-3.4969],\n",
       "         [-3.5764],\n",
       "         [-3.1834],\n",
       "         [-3.1471],\n",
       "         [-3.5230],\n",
       "         [-3.9157],\n",
       "         [-3.5596],\n",
       "         [-4.3244],\n",
       "         [-4.5635],\n",
       "         [-4.9413],\n",
       "         [-6.1557],\n",
       "         [-4.8437],\n",
       "         [-4.2198],\n",
       "         [-4.3895],\n",
       "         [-3.6583],\n",
       "         [-3.3863],\n",
       "         [-3.3199],\n",
       "         [-3.3749],\n",
       "         [-3.3820],\n",
       "         [-3.6591],\n",
       "         [-3.5286],\n",
       "         [-3.2800],\n",
       "         [-3.5507],\n",
       "         [-3.4977],\n",
       "         [-4.1644],\n",
       "         [-3.6112],\n",
       "         [-3.5931],\n",
       "         [-4.5888],\n",
       "         [-3.9744],\n",
       "         [-4.4816],\n",
       "         [-4.2984],\n",
       "         [-3.9063],\n",
       "         [-3.3388],\n",
       "         [-3.2551],\n",
       "         [-3.3415],\n",
       "         [-3.0082],\n",
       "         [-3.5543],\n",
       "         [-3.3321],\n",
       "         [-3.0716],\n",
       "         [-3.1934],\n",
       "         [-3.2417],\n",
       "         [-3.2633],\n",
       "         [-3.8958],\n",
       "         [-3.7070],\n",
       "         [-3.9806],\n",
       "         [-3.5733],\n",
       "         [-3.6190],\n",
       "         [-4.5631],\n",
       "         [-4.5815],\n",
       "         [-4.9646],\n",
       "         [-5.1390],\n",
       "         [-3.7413],\n",
       "         [-4.0615],\n",
       "         [-3.8428],\n",
       "         [-3.2692],\n",
       "         [-3.2975],\n",
       "         [-3.1633],\n",
       "         [-3.2210],\n",
       "         [-3.5042],\n",
       "         [-3.4029],\n",
       "         [-3.2100],\n",
       "         [-3.5558],\n",
       "         [-3.6365],\n",
       "         [-3.9302],\n",
       "         [-3.7474],\n",
       "         [-3.3246],\n",
       "         [-3.3972],\n",
       "         [-4.3609],\n",
       "         [-4.3786],\n",
       "         [-3.9983],\n",
       "         [-4.3563],\n",
       "         [-3.9193],\n",
       "         [-4.0571],\n",
       "         [-3.3795],\n",
       "         [-3.5081],\n",
       "         [-3.2962],\n",
       "         [-3.5691],\n",
       "         [-3.1294],\n",
       "         [-3.1752],\n",
       "         [-3.3867],\n",
       "         [-3.5402],\n",
       "         [-3.3794],\n",
       "         [-3.4564],\n",
       "         [-3.7772],\n",
       "         [-3.8894],\n",
       "         [-4.1707],\n",
       "         [-3.7368],\n",
       "         [-4.2123],\n",
       "         [-4.3321],\n",
       "         [-4.2381],\n",
       "         [-4.9347],\n",
       "         [-3.6995],\n",
       "         [-3.8452],\n",
       "         [-3.5255],\n",
       "         [-3.7378],\n",
       "         [-3.1274],\n",
       "         [-3.7856],\n",
       "         [-3.5158],\n",
       "         [-3.5074],\n",
       "         [-3.1554],\n",
       "         [-3.5955],\n",
       "         [-3.1269],\n",
       "         [-3.7124],\n",
       "         [-4.0949],\n",
       "         [-3.8515],\n",
       "         [-3.9536],\n",
       "         [-4.1617],\n",
       "         [-3.6696],\n",
       "         [-4.1439],\n",
       "         [-3.5555],\n",
       "         [-3.5220],\n",
       "         [-2.9223],\n",
       "         [-3.6839],\n",
       "         [-3.6400],\n",
       "         [-4.1239],\n",
       "         [-3.7241],\n",
       "         [-3.9157],\n",
       "         [-3.3957],\n",
       "         [-3.0946],\n",
       "         [-2.6841],\n",
       "         [-2.6918],\n",
       "         [-3.3284],\n",
       "         [-4.1367],\n",
       "         [-4.4131],\n",
       "         [-4.0179],\n",
       "         [-4.0330],\n",
       "         [-4.0894],\n",
       "         [-3.5421],\n",
       "         [-4.2780],\n",
       "         [-3.3691],\n",
       "         [-3.7307],\n",
       "         [-4.1914],\n",
       "         [-3.8268],\n",
       "         [-3.7142],\n",
       "         [-3.9609],\n",
       "         [-3.9654],\n",
       "         [-3.9487],\n",
       "         [-3.2029],\n",
       "         [-2.6636],\n",
       "         [-3.3193],\n",
       "         [-3.5208],\n",
       "         [-3.8772],\n",
       "         [-3.8674],\n",
       "         [-3.7065],\n",
       "         [-2.9449],\n",
       "         [-3.3505],\n",
       "         [-3.8679],\n",
       "         [-3.6632],\n",
       "         [-4.0433],\n",
       "         [-3.7711],\n",
       "         [-3.7215],\n",
       "         [-3.3755],\n",
       "         [-3.3671],\n",
       "         [-3.0747],\n",
       "         [-3.4506],\n",
       "         [-3.4243],\n",
       "         [-3.0927],\n",
       "         [-3.6858],\n",
       "         [-3.3151],\n",
       "         [-3.7624],\n",
       "         [-3.7186],\n",
       "         [-3.5283],\n",
       "         [-4.2927],\n",
       "         [-3.4690],\n",
       "         [-3.6837],\n",
       "         [-3.6410],\n",
       "         [-3.3777],\n",
       "         [-3.1442],\n",
       "         [-4.0947],\n",
       "         [-3.3291],\n",
       "         [-3.2870],\n",
       "         [-3.1257],\n",
       "         [-3.2246],\n",
       "         [-3.0459],\n",
       "         [-3.2232],\n",
       "         [-3.1559],\n",
       "         [-3.5022],\n",
       "         [-3.5992],\n",
       "         [-3.4859],\n",
       "         [-3.5347],\n",
       "         [-3.2566],\n",
       "         [-3.4470],\n",
       "         [-3.6628],\n",
       "         [-3.4773],\n",
       "         [-3.3128],\n",
       "         [-3.0435],\n",
       "         [-2.8978]]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(jk['4.3']['cls'])[:,2400:2800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,100):\n",
    "#     data[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31719548\n"
     ]
    }
   ],
   "source": [
    "total_params=sum(p.numel() for p in extractor.parameters())\n",
    "total_params+= sum(p.numel() for p in topdown.parameters())\n",
    "total_params+= sum(p.numel() for p in classifier.parameters())\n",
    "total_params+= sum(p.numel() for p in bboxregression.parameters())\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "def train_with_accumulation(epochs: int, training_data, validation_data=None, accumulation_steps=4):\n",
    "    # Set models to training mode\n",
    "    extractor.train()\n",
    "    topdown.train()\n",
    "    classifier.train()\n",
    "    bboxregression.train()\n",
    "    \n",
    "    if hasattr(extractor, 'gradient_checkpointing_enable'):\n",
    "        extractor.gradient_checkpointing_enable()\n",
    "    if hasattr(topdown, 'gradient_checkpointing_enable'):\n",
    "        topdown.gradient_checkpointing_enable()\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        list(extractor.parameters()) +\n",
    "        list(topdown.parameters()) +\n",
    "        list(classifier.parameters()) +\n",
    "        list(bboxregression.parameters()), \n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    loss_history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        try:\n",
    "            for batch_idx, (image, bbox) in enumerate(training_data):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with autocast('cuda'):\n",
    "                    model_pred = forward(image.cuda())\n",
    "                    ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "                scaler.scale(ll).backward()\n",
    "                \n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                batch_loss = ll.item() * accumulation_steps  # Unscale for logging\n",
    "                epoch_loss += batch_loss\n",
    "                running_loss += batch_loss\n",
    "                batch_count += 1\n",
    "                \n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    avg_running_loss = running_loss / 10\n",
    "                    print(f\"Batch {batch_idx + 1}: Avg Loss = {avg_running_loss:.6f}\")\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                # Memory \n",
    "                del image , model_pred , bbox\n",
    "                del ll\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "        except Exception as e :\n",
    "            print (e)\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "            break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"INTERRUPTED!!\")\n",
    "            return loss_history   \n",
    "\n",
    "                \n",
    "        if batch_count % accumulation_steps != 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "        loss_history[epoch] = avg_epoch_loss\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Epoch {epoch + 1} Average Loss: {avg_epoch_loss:.6f}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        \n",
    "        # Cleanup at epoch end\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss_history\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "training_data = DataLoader(\n",
    "    data,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=4,     \n",
    "    pin_memory=True,        \n",
    "    persistent_workers=True, \n",
    "    prefetch_factor=4,       \n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "validation_data = DataLoader(vali_data,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=4,     \n",
    "    pin_memory=True,         \n",
    "    persistent_workers=True, \n",
    "    prefetch_factor=4,       \n",
    "    drop_last=True,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "------------------------------\n",
      "Batch 10: Avg Loss = 101.507450\n",
      "Batch 20: Avg Loss = 191.673210\n",
      "Batch 30: Avg Loss = 106.350500\n",
      "Batch 40: Avg Loss = 57.371157\n",
      "Batch 50: Avg Loss = 43.992403\n",
      "Batch 60: Avg Loss = 37.837786\n",
      "Batch 70: Avg Loss = 26.042994\n",
      "Batch 80: Avg Loss = 15.267632\n",
      "Batch 90: Avg Loss = 9.869727\n",
      "Batch 100: Avg Loss = 11.371710\n",
      "Batch 110: Avg Loss = 7.267350\n",
      "Batch 120: Avg Loss = 55.859939\n",
      "Batch 130: Avg Loss = 6.483840\n",
      "Batch 140: Avg Loss = 6.131270\n",
      "Batch 150: Avg Loss = 5.733312\n",
      "Batch 160: Avg Loss = 5.793077\n",
      "Batch 170: Avg Loss = 5.104185\n",
      "Batch 180: Avg Loss = 5.244019\n",
      "Batch 190: Avg Loss = 5.447075\n",
      "Batch 200: Avg Loss = 5.235138\n",
      "Batch 210: Avg Loss = 4.853832\n",
      "Batch 220: Avg Loss = 4.898820\n",
      "Batch 230: Avg Loss = 17.053326\n",
      "Batch 240: Avg Loss = 4.743194\n",
      "Batch 250: Avg Loss = 5.727100\n",
      "Batch 260: Avg Loss = 4.524421\n",
      "Batch 270: Avg Loss = 4.521035\n",
      "Batch 280: Avg Loss = 4.662802\n",
      "Batch 290: Avg Loss = 4.571929\n",
      "Batch 300: Avg Loss = 13.792609\n",
      "Batch 310: Avg Loss = 5.140172\n",
      "Batch 320: Avg Loss = 5.012590\n",
      "Batch 330: Avg Loss = 4.689723\n",
      "Batch 340: Avg Loss = 4.595858\n",
      "Batch 350: Avg Loss = 4.512109\n",
      "Batch 360: Avg Loss = 4.607913\n",
      "Batch 370: Avg Loss = 4.500398\n",
      "Batch 380: Avg Loss = 4.560592\n",
      "Batch 390: Avg Loss = 4.530958\n",
      "Batch 400: Avg Loss = 4.453815\n",
      "Batch 410: Avg Loss = 4.438533\n",
      "Batch 420: Avg Loss = 4.382864\n",
      "Batch 430: Avg Loss = 4.332494\n",
      "Batch 440: Avg Loss = 4.335462\n",
      "Batch 450: Avg Loss = 4.528963\n",
      "Batch 460: Avg Loss = 6.270565\n",
      "Batch 470: Avg Loss = 4.294707\n",
      "Batch 480: Avg Loss = 4.156791\n",
      "Batch 490: Avg Loss = 4.013224\n",
      "Batch 500: Avg Loss = 4.032702\n",
      "Batch 510: Avg Loss = 4.060520\n",
      "Batch 520: Avg Loss = 4.033546\n",
      "Batch 530: Avg Loss = 5.902282\n",
      "Batch 540: Avg Loss = 5.753732\n",
      "Batch 550: Avg Loss = 4.084296\n",
      "Batch 560: Avg Loss = 3.893282\n",
      "Batch 570: Avg Loss = 4.301539\n",
      "Batch 580: Avg Loss = 4.099971\n",
      "Batch 590: Avg Loss = 3.990144\n",
      "Batch 600: Avg Loss = 3.913102\n",
      "Batch 610: Avg Loss = 3.961985\n",
      "Batch 620: Avg Loss = 4.036494\n",
      "Batch 630: Avg Loss = 3.923131\n",
      "Batch 640: Avg Loss = 5.919742\n",
      "Batch 650: Avg Loss = 4.069192\n",
      "Batch 660: Avg Loss = 5.176403\n",
      "Batch 670: Avg Loss = 4.133596\n",
      "Batch 680: Avg Loss = 4.148700\n",
      "Batch 690: Avg Loss = 4.239178\n",
      "Batch 700: Avg Loss = 4.158585\n",
      "Batch 710: Avg Loss = 4.146739\n",
      "Batch 720: Avg Loss = 4.142474\n",
      "Batch 730: Avg Loss = 4.095743\n",
      "Batch 740: Avg Loss = 3.987845\n",
      "Batch 750: Avg Loss = 4.108560\n",
      "Batch 760: Avg Loss = 4.072527\n",
      "Batch 770: Avg Loss = 4.069333\n",
      "Batch 780: Avg Loss = 4.911424\n",
      "Batch 790: Avg Loss = 4.022148\n",
      "Batch 800: Avg Loss = 4.027449\n",
      "Batch 810: Avg Loss = 4.019609\n",
      "Batch 820: Avg Loss = 4.035832\n",
      "Batch 830: Avg Loss = 3.967284\n",
      "Batch 840: Avg Loss = 4.393481\n",
      "Batch 850: Avg Loss = 3.813801\n",
      "Batch 860: Avg Loss = 3.873637\n",
      "Batch 870: Avg Loss = 3.936549\n",
      "Batch 880: Avg Loss = 3.841526\n",
      "Batch 890: Avg Loss = 3.817372\n",
      "Batch 900: Avg Loss = 4.082186\n",
      "Batch 910: Avg Loss = 4.919880\n",
      "Batch 920: Avg Loss = 3.918544\n",
      "Batch 930: Avg Loss = 4.008158\n",
      "Batch 940: Avg Loss = 3.898596\n",
      "Batch 950: Avg Loss = 3.941300\n",
      "Batch 960: Avg Loss = 4.582752\n",
      "Batch 970: Avg Loss = 3.989865\n",
      "Batch 980: Avg Loss = 3.950709\n",
      "Batch 990: Avg Loss = 4.019746\n",
      "Batch 1000: Avg Loss = 4.076834\n",
      "Batch 1010: Avg Loss = 4.807277\n",
      "Batch 1020: Avg Loss = 4.010018\n",
      "Batch 1030: Avg Loss = 5.848350\n",
      "Batch 1040: Avg Loss = 4.034626\n",
      "Batch 1050: Avg Loss = 3.770952\n",
      "Batch 1060: Avg Loss = 3.821457\n",
      "Batch 1070: Avg Loss = 4.031801\n",
      "Batch 1080: Avg Loss = 3.919378\n",
      "Batch 1090: Avg Loss = 3.992466\n",
      "Batch 1100: Avg Loss = 3.850940\n",
      "Batch 1110: Avg Loss = 3.876333\n",
      "Batch 1120: Avg Loss = 3.703631\n",
      "Batch 1130: Avg Loss = 4.061541\n",
      "Batch 1140: Avg Loss = 3.854856\n",
      "Batch 1150: Avg Loss = 3.953460\n",
      "Batch 1160: Avg Loss = 3.885858\n",
      "Batch 1170: Avg Loss = 3.910079\n",
      "Batch 1180: Avg Loss = 3.861460\n",
      "Batch 1190: Avg Loss = 3.800322\n",
      "Batch 1200: Avg Loss = 3.835408\n",
      "Batch 1210: Avg Loss = 3.732037\n",
      "Batch 1220: Avg Loss = 3.934764\n",
      "Batch 1230: Avg Loss = 3.751530\n",
      "Batch 1240: Avg Loss = 3.753213\n",
      "Batch 1250: Avg Loss = 3.922895\n",
      "Batch 1260: Avg Loss = 3.775758\n",
      "Batch 1270: Avg Loss = 3.779880\n",
      "Batch 1280: Avg Loss = 3.759379\n",
      "Batch 1290: Avg Loss = 3.794634\n",
      "Batch 1300: Avg Loss = 3.833306\n",
      "Batch 1310: Avg Loss = 3.811302\n",
      "Batch 1320: Avg Loss = 3.662845\n",
      "Batch 1330: Avg Loss = 3.836128\n",
      "Batch 1340: Avg Loss = 4.061711\n",
      "Batch 1350: Avg Loss = 7.344424\n",
      "Batch 1360: Avg Loss = 3.797272\n",
      "Batch 1370: Avg Loss = 3.782469\n",
      "Batch 1380: Avg Loss = 3.784580\n",
      "Batch 1390: Avg Loss = 6.598807\n",
      "Batch 1400: Avg Loss = 3.899719\n",
      "Batch 1410: Avg Loss = 3.739886\n",
      "Batch 1420: Avg Loss = 3.784160\n",
      "Batch 1430: Avg Loss = 3.750007\n",
      "Batch 1440: Avg Loss = 3.772508\n",
      "Batch 1450: Avg Loss = 3.798424\n",
      "Batch 1460: Avg Loss = 3.763681\n",
      "Batch 1470: Avg Loss = 3.788830\n",
      "Batch 1480: Avg Loss = 3.832042\n",
      "Batch 1490: Avg Loss = 5.448205\n",
      "Batch 1500: Avg Loss = 3.757814\n",
      "Batch 1510: Avg Loss = 3.623734\n",
      "Batch 1520: Avg Loss = 3.595062\n",
      "Batch 1530: Avg Loss = 3.758730\n",
      "Batch 1540: Avg Loss = 3.769169\n",
      "Batch 1550: Avg Loss = 3.587212\n",
      "Batch 1560: Avg Loss = 8.515376\n",
      "Batch 1570: Avg Loss = 3.590240\n",
      "Batch 1580: Avg Loss = 3.672564\n",
      "Batch 1590: Avg Loss = 3.572302\n",
      "Batch 1600: Avg Loss = 3.828997\n",
      "Batch 1610: Avg Loss = 3.516479\n",
      "------------------------------\n",
      "Epoch 1 Average Loss: 8.252838\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "lossdata = train_with_accumulation(epochs = 1, training_data = training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Lossfunction()\n",
    "extractor.eval()\n",
    "topdown.eval()\n",
    "classifier.eval()\n",
    "bboxregression.eval()\n",
    "accumulation_steps = 4\n",
    "for batch_idx, (image, bbox) in enumerate(validation_data):\n",
    "\n",
    "    with autocast('cuda'):\n",
    "        model_pred = forward(image.cuda())\n",
    "        ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "    del image , model_pred , bbox\n",
    "    print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 2.11 GB\n",
      "Cached: 2.21 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   git config --global user.email \"agarwalvipul577@gmail.com\"\n",
    "#   git config --global user.name \"VIPUL577\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 640])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1000][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, threshold , layers = ['4.0','4.1','4.2','4.3']):\n",
    "    s=forward(vali_data[i][0].unsqueeze(0).cuda())\n",
    "    t= data[i][1]\n",
    "    ls = loss(s,t)\n",
    "    print(f\"Loss:{ls}\")\n",
    "    for key,layer in enumerate(layers):\n",
    "        print(f\"prediction: {(nn.Sigmoid()(s[layer]['cls'].cpu())>threshold).sum()} out of total {s[layer]['cls'].cpu().shape} \")\n",
    "        print(f\"truth: {t[len(layers)-key-1]['cls_targets'].sum()} out of total {t[len(layers)-key-1]['cls_targets'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:15410.435546875\n",
      "prediction: 149654 out of total torch.Size([1, 307200, 1]) \n",
      "truth: 32 out of total torch.Size([1, 307200, 1])\n",
      "prediction: 37679 out of total torch.Size([1, 76800, 1]) \n",
      "truth: 3 out of total torch.Size([1, 76800, 1])\n",
      "prediction: 9439 out of total torch.Size([1, 19200, 1]) \n",
      "truth: 0 out of total torch.Size([1, 19200, 1])\n",
      "prediction: 2369 out of total torch.Size([1, 4800, 1]) \n",
      "truth: 0 out of total torch.Size([1, 4800, 1])\n"
     ]
    }
   ],
   "source": [
    "check(1080, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:93.85011291503906\n",
      "prediction: 5641 out of total torch.Size([1, 307200, 1]) \n",
      "truth: 352 out of total torch.Size([1, 307200, 1])\n",
      "prediction: 1418 out of total torch.Size([1, 76800, 1]) \n",
      "truth: 127 out of total torch.Size([1, 76800, 1])\n",
      "prediction: 367 out of total torch.Size([1, 19200, 1]) \n",
      "truth: 13 out of total torch.Size([1, 19200, 1])\n",
      "prediction: 91 out of total torch.Size([1, 4800, 1]) \n",
      "truth: 0 out of total torch.Size([1, 4800, 1])\n"
     ]
    }
   ],
   "source": [
    "check(1081, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:3.1815199851989746\n",
      "prediction: 0 out of total torch.Size([1, 307200, 1]) \n",
      "truth: 352 out of total torch.Size([1, 307200, 1])\n",
      "prediction: 0 out of total torch.Size([1, 76800, 1]) \n",
      "truth: 127 out of total torch.Size([1, 76800, 1])\n",
      "prediction: 0 out of total torch.Size([1, 19200, 1]) \n",
      "truth: 13 out of total torch.Size([1, 19200, 1])\n",
      "prediction: 0 out of total torch.Size([1, 4800, 1]) \n",
      "truth: 0 out of total torch.Size([1, 4800, 1])\n"
     ]
    }
   ],
   "source": [
    "check(1081, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(extractor.state_dict(),'/home/faces2.0/models/extractor.pt')\n",
    "torch.save(topdown.state_dict(),'/home/faces2.0/models/topdown.pt')\n",
    "torch.save(classifier.state_dict(),'/home/faces2.0/models/classifier.pt')\n",
    "torch.save(bboxregression.state_dict(),'/home/faces2.0/models/bboxregression.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
