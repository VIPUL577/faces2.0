{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faces2.0/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_528/371093317.py:15: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "from FPN import Features, FPNetwork , classificationhead , bboxhead\n",
    "from Loss import Lossfunction\n",
    "from datasets import load_dataset\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import  GradScaler\n",
    "from torch.amp import autocast\n",
    "import random\n",
    "import gc\n",
    "from dataset_convert import AnchorGenerator, FaceDetectionDataset\n",
    "# device = torch.device(\"mps\")\n",
    "scaler = GradScaler()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/home/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/home/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resnet50 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_resnet50', pretrained=True)\n",
    "\n",
    "resnet_backbone = nn.Sequential(*list(resnet50.children())[:-2]).to(device)\n",
    "layers_r50= {'4.0':256,  #-> 160,160 \n",
    "     '4.1':512,  #->  80,80\n",
    "     '4.2':1024, #-> 40,40\n",
    "     '4.3':2048  #-> 20,20\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/faces2.0/.conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model = model.features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"CUHK-CSE/wider_face\")\n",
    "train_dataset = dataset['train'].with_format(\"torch\")\n",
    "val_dataset = dataset['validation'].with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Features(resnet_backbone,layers=list(layers_r50.keys()))\n",
    "topdown = FPNetwork(in_channels=layers_r50, out_channels=256)\n",
    "classifier = classificationhead(channels=256, num_anchors= 12, num_of_classes= 1)\n",
    "bboxregression = bboxhead(channels= 256 , num_anchors= 12)\n",
    "loss =Lossfunction(lambd=10)\n",
    "anchors = AnchorGenerator()\n",
    "data = FaceDetectionDataset(train_dataset,anchors)\n",
    "vali_data = FaceDetectionDataset(val_dataset,anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd_extractor = torch.load('/home/faces2.0/models/extractor.pt',map_location=torch.device('cpu'))\n",
    "# sd_classifier = torch.load('/home/faces2.0/models/classifier.pt',map_location=torch.device('cpu'))\n",
    "# sd_bboxregression = torch.load('/home/faces2.0/models/bboxregression.pt',map_location=torch.device('cpu'))\n",
    "# sd_topdown = torch.load('/home/faces2.0/models/topdown.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "# extractor.load_state_dict(sd_extractor)\n",
    "# topdown.load_state_dict(sd_topdown)\n",
    "# classifier.load_state_dict(sd_classifier)\n",
    "# bboxregression.load_state_dict(sd_bboxregression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor = Features(model,['3','6', '13','18'])\n",
    "# topdown = FPNetwork(out_channels=256)\n",
    "# classifier = classificationhead(channels=256, num_anchors= 12, num_of_classes= 1)\n",
    "# bboxregression = bboxhead(channels= 256 , num_anchors= 12)\n",
    "# loss =Lossfunction(lambd=10)\n",
    "# anchors = AnchorGenerator()\n",
    "# data = FaceDetectionDataset(train_dataset,anchors)\n",
    "# vali_data = FaceDetectionDataset(val_dataset,anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.13 GB\n",
      "Cached: 0.14 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(p):\n",
    "    features = extractor.extract(p)\n",
    "    newfeatures = topdown(features)\n",
    "    output = {}\n",
    "    for key in list(newfeatures.keys()):\n",
    "        temp = {}\n",
    "        temp[\"bbox\"] = bboxregression(newfeatures[key])\n",
    "        temp[\"cls\"] = classifier(newfeatures[key])\n",
    "        output[key] = temp\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99367.1953, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kk =data[10310][0].unsqueeze(0).cuda()\n",
    "jk = forward(kk)\n",
    "ll = loss(jk, data[10310][1])\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5340],\n",
       "         [0.4859],\n",
       "         [0.3539],\n",
       "         ...,\n",
       "         [0.2979],\n",
       "         [0.6345],\n",
       "         [0.3625]]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(jk['4.3']['cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savea():\n",
    "    torch.save(extractor.state_dict(),'/home/faces2.0/models/extractor.pt')\n",
    "    torch.save(topdown.state_dict(),'/home/faces2.0/models/topdown.pt')\n",
    "    torch.save(classifier.state_dict(),'/home/faces2.0/models/classifier.pt')\n",
    "    torch.save(bboxregression.state_dict(),'/home/faces2.0/models/bboxregression.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31719572\n"
     ]
    }
   ],
   "source": [
    "total_params=sum(p.numel() for p in extractor.parameters())\n",
    "total_params+= sum(p.numel() for p in topdown.parameters())\n",
    "total_params+= sum(p.numel() for p in classifier.parameters())\n",
    "total_params+= sum(p.numel() for p in bboxregression.parameters())\n",
    "\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def train_with_accumulation(epochs: int, training_data, validation_data=None, accumulation_steps=4):\n",
    "    # Set models to training mode\n",
    "    extractor.train()\n",
    "    topdown.train()\n",
    "    classifier.train()\n",
    "    bboxregression.train()\n",
    "    \n",
    "    # Enable gradient checkpointing\n",
    "    if hasattr(extractor, 'gradient_checkpointing_enable'):\n",
    "        extractor.gradient_checkpointing_enable()\n",
    "    if hasattr(topdown, 'gradient_checkpointing_enable'):\n",
    "        topdown.gradient_checkpointing_enable()\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        list(extractor.parameters()) +\n",
    "        list(topdown.parameters()) +\n",
    "        list(classifier.parameters()) +\n",
    "        list(bboxregression.parameters()), \n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    loss_history = {}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        try:\n",
    "            for batch_idx, (image, bbox) in enumerate(training_data):\n",
    "                # Mixed precision forward pass\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with autocast('cuda'):\n",
    "                    model_pred = forward(image.cuda())\n",
    "                    ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "                # del image , model_pred , bbox\n",
    "                # Backward pass\n",
    "                scaler.scale(ll).backward()\n",
    "                \n",
    "                # Step optimizer every accumulation_steps\n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    # for name, param in classifier.named_parameters():\n",
    "                    # # print(param.grad)\n",
    "                    #     if param.grad is not None:\n",
    "                    #         print(f\"Gradients for {name}:\")\n",
    "                    #         print(param.grad)\n",
    "\n",
    "                    #     else :\n",
    "                    #         print(\"swahaa\")\n",
    "                            \n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                # Accumulate loss\n",
    "                batch_loss = ll.item() * accumulation_steps  # Unscale for logging\n",
    "                epoch_loss += batch_loss\n",
    "                running_loss += batch_loss\n",
    "                batch_count += 1\n",
    "                \n",
    "                # Print progress\n",
    "                if (batch_idx + 1) % 10 == 0:\n",
    "                    avg_running_loss = running_loss / 10\n",
    "                    # print(\"-\" * 30)\n",
    "                    print(f\"Batch {batch_idx + 1}: Avg Loss = {avg_running_loss:.6f}\")\n",
    "                    # print(\"-\" * 30)\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                # Memory \n",
    "                del ll\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                # if batch_idx == 0:\n",
    "                #     # print(image.shape)\n",
    "                #     break\n",
    "                del image , model_pred , bbox\n",
    "\n",
    "        except Exception as e :\n",
    "            print (e)\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "            print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "            break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"INTERRUPTED!!\")\n",
    "            return loss_history   \n",
    "\n",
    "                \n",
    "        if batch_count % accumulation_steps != 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "        loss_history[epoch] = avg_epoch_loss\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Epoch {epoch + 1} Average Loss: {avg_epoch_loss:.6f}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        \n",
    "        # Cleanup at epoch end\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    # save()\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "training_data = DataLoader(\n",
    "    data,\n",
    "    batch_size=8, \n",
    "    num_workers=4,     # Reduce if GPU memory is full\n",
    "    pin_memory=True,         # Faster CPU->GPU transfer\n",
    "    persistent_workers=True, # Reuse workers across epochs\n",
    "    prefetch_factor=4,       # Prefetch more batches\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "validation_data = DataLoader(vali_data,\n",
    "    batch_size=batch_size, \n",
    "    num_workers=4,     # Reduce if GPU memory is full\n",
    "    pin_memory=True,         # Faster CPU->GPU transfer\n",
    "    persistent_workers=True, # Reuse workers across epochs\n",
    "    prefetch_factor=4,       # Prefetch more batches\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "------------------------------\n",
      "Batch 10: Avg Loss = 2752.284961\n",
      "Batch 20: Avg Loss = 2905.721875\n",
      "Batch 30: Avg Loss = 47419.616541\n",
      "Batch 40: Avg Loss = 2749.637842\n",
      "Batch 50: Avg Loss = 1941.398328\n",
      "Batch 60: Avg Loss = 1926.071149\n",
      "Batch 70: Avg Loss = 1444.090002\n",
      "Batch 80: Avg Loss = 1710.181116\n",
      "Batch 90: Avg Loss = 5421.949655\n",
      "Batch 100: Avg Loss = 1838.414673\n",
      "Batch 110: Avg Loss = 1485.278040\n",
      "Batch 120: Avg Loss = 1372.068622\n",
      "Batch 130: Avg Loss = 2097.322662\n",
      "Batch 140: Avg Loss = 1508.403513\n",
      "Batch 150: Avg Loss = 2198.986566\n",
      "Batch 160: Avg Loss = 2093.737555\n",
      "Batch 170: Avg Loss = 1366.074707\n",
      "Batch 180: Avg Loss = 1745.182330\n",
      "Batch 190: Avg Loss = 1678.669873\n",
      "Batch 200: Avg Loss = 12291.848309\n",
      "Batch 210: Avg Loss = 1444.694391\n",
      "Batch 220: Avg Loss = 4356.833752\n",
      "Batch 230: Avg Loss = 32713.788766\n",
      "Batch 240: Avg Loss = 34598.653943\n",
      "Batch 250: Avg Loss = 1567.134772\n",
      "Batch 260: Avg Loss = 2370.392535\n",
      "INTERRUPTED!!\n"
     ]
    }
   ],
   "source": [
    "lossdata = train_with_accumulation(epochs = 1, training_data = training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Lossfunction()\n",
    "extractor.eval()\n",
    "topdown.eval()\n",
    "classifier.eval()\n",
    "bboxregression.eval()\n",
    "accumulation_steps = 4\n",
    "for batch_idx, (image, bbox) in enumerate(validation_data):\n",
    "\n",
    "    with autocast('cuda'):\n",
    "        model_pred = forward(image.cuda())\n",
    "        ll = loss(model_pred, bbox) / accumulation_steps  # Scale loss\n",
    "    del image , model_pred , bbox\n",
    "    print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 4.44 GB\n",
      "Cached: 4.80 GB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 640, 640])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1000][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(i, threshold , layers = ['4.0','4.1','4.2','4.3']):\n",
    "    s=forward(vali_data[i][0].unsqueeze(0).cuda())\n",
    "    t= vali_data[i][1]\n",
    "    ls = loss(s,t)\n",
    "    print(f\"Loss:{ls}\")\n",
    "    print(torch.sigmoid(s['4.1']['cls']))\n",
    "    for key,layer in enumerate(layers):\n",
    "        print(f\"prediction: {(torch.sigmoid(s[layer]['cls']).cpu()>threshold).sum()} out of total {s[layer]['cls'].cpu().shape} \")\n",
    "        print(f\"truth: {t[len(layers)-key-1]['cls_targets'].sum()} out of total {t[len(layers)-key-1]['cls_targets'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset_convert.FaceDetectionDataset at 0x7f024d369550>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:53560.125\n",
      "tensor([[[0.5186],\n",
      "         [0.5069],\n",
      "         [0.5119],\n",
      "         ...,\n",
      "         [0.5304],\n",
      "         [0.5226],\n",
      "         [0.5248]]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "prediction: 187398 out of total torch.Size([1, 307200, 1]) \n",
      "truth: 0 out of total torch.Size([1, 307200, 1])\n",
      "prediction: 51337 out of total torch.Size([1, 76800, 1]) \n",
      "truth: 0 out of total torch.Size([1, 76800, 1])\n",
      "prediction: 12921 out of total torch.Size([1, 19200, 1]) \n",
      "truth: 0 out of total torch.Size([1, 19200, 1])\n",
      "prediction: 2927 out of total torch.Size([1, 4800, 1]) \n",
      "truth: 32 out of total torch.Size([1, 4800, 1])\n"
     ]
    }
   ],
   "source": [
    "check(1109, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savea()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
